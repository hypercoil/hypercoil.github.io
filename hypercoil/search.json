[
  {
    "objectID": "api/functional.corr.html",
    "href": "api/functional.corr.html",
    "title": "functional.corr",
    "section": "",
    "text": "functional.corr(X, **params)\nPearson correlation of variables in a tensor batch.\nThe correlation is obtained via normalisation of the covariance. Given a covariance matrix :math:\\hat{\\Sigma} \\in \\mathbb{R}^{n \\times n}, each entry of the correlation matrix :math:R \\in \\mathbb{R}^{n \\times n} is defined according to\n:math:R_{ij} = \\frac{\\hat{\\Sigma}_{ij}}{\\sqrt{\\hat{\\Sigma}_{ii}} \\sqrt{\\hat{\\Sigma}_{jj}}}\n:Dimension: Input : :math:(N, *, C, obs) or :math:(N, *, obs, C) N denotes batch size, * denotes any number of intervening dimensions, C denotes number of data channels or variables to be correlated, obs denotes number of observations per channel Weight : :math:(obs) or :math:(obs, obs) As above Output : :math:(N, *, C, C) As above\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\nTensor\nTensor containing a sample of multivariate observations. Each slice along the last axis corresponds to an observation, and each slice along the penultimate axis corresponds to a data channel or more generally a variable.\nrequired\n\n\nrowvar\nbool (default True)\nIndicates that the last axis of the input tensor is the observation axis and the penultimate axis is the variable axis. If False, then this relationship is transposed.\nrequired\n\n\nbias\nbool (default False)\nIndicates that the biased normalisation (i.e., division by N in the unweighted case) should be performed. By default, normalisation of the covariance is unbiased (i.e., division by N - 1).\nrequired\n\n\nddof\nint or None (default None)\nDegrees of freedom for normalisation. If this is specified, it overrides the normalisation factor automatically determined using the bias parameter.\nrequired\n\n\nweight\nTensor or None (default None)\nTensor containing importance or coupling weights for the observations. If this tensor is 1-dimensional, each entry weights the corresponding observation in the covariance computation. If it is 2-dimensional, then it must be square, symmetric, and positive semidefinite. In this case, diagonal entries again correspond to relative importances, while off-diagonal entries indicate coupling factors. For instance, a banded or multi-diagonal tensor can be used to specify inter-temporal coupling for a time series covariance.\nrequired\n\n\nl2\nnonnegative float (default 0)\nL2 regularisation term to add to the maximum likelihood estimate of the covariance matrix. This can be set to a positive value to obtain an intermediate for estimating the regularised inverse covariance.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nR\nTensor\nPearson correlation matrix of the variables in the input tensor.\n\n\n\n\n\n\ncov: Empirical covariance matrix partialcorr: Partial correlation matrix conditionalcorr: Conditional correlation matrix",
    "crumbs": [
      "hypercoil",
      "functional.corr"
    ]
  },
  {
    "objectID": "api/functional.corr.html#parameters",
    "href": "api/functional.corr.html#parameters",
    "title": "functional.corr",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nX\nTensor\nTensor containing a sample of multivariate observations. Each slice along the last axis corresponds to an observation, and each slice along the penultimate axis corresponds to a data channel or more generally a variable.\nrequired\n\n\nrowvar\nbool (default True)\nIndicates that the last axis of the input tensor is the observation axis and the penultimate axis is the variable axis. If False, then this relationship is transposed.\nrequired\n\n\nbias\nbool (default False)\nIndicates that the biased normalisation (i.e., division by N in the unweighted case) should be performed. By default, normalisation of the covariance is unbiased (i.e., division by N - 1).\nrequired\n\n\nddof\nint or None (default None)\nDegrees of freedom for normalisation. If this is specified, it overrides the normalisation factor automatically determined using the bias parameter.\nrequired\n\n\nweight\nTensor or None (default None)\nTensor containing importance or coupling weights for the observations. If this tensor is 1-dimensional, each entry weights the corresponding observation in the covariance computation. If it is 2-dimensional, then it must be square, symmetric, and positive semidefinite. In this case, diagonal entries again correspond to relative importances, while off-diagonal entries indicate coupling factors. For instance, a banded or multi-diagonal tensor can be used to specify inter-temporal coupling for a time series covariance.\nrequired\n\n\nl2\nnonnegative float (default 0)\nL2 regularisation term to add to the maximum likelihood estimate of the covariance matrix. This can be set to a positive value to obtain an intermediate for estimating the regularised inverse covariance.\nrequired",
    "crumbs": [
      "hypercoil",
      "functional.corr"
    ]
  },
  {
    "objectID": "api/functional.corr.html#returns",
    "href": "api/functional.corr.html#returns",
    "title": "functional.corr",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nR\nTensor\nPearson correlation matrix of the variables in the input tensor.",
    "crumbs": [
      "hypercoil",
      "functional.corr"
    ]
  },
  {
    "objectID": "api/functional.corr.html#see-also",
    "href": "api/functional.corr.html#see-also",
    "title": "functional.corr",
    "section": "",
    "text": "cov: Empirical covariance matrix partialcorr: Partial correlation matrix conditionalcorr: Conditional correlation matrix",
    "crumbs": [
      "hypercoil",
      "functional.corr"
    ]
  },
  {
    "objectID": "api/loss.nn.EntropyLoss.html",
    "href": "api/loss.nn.EntropyLoss.html",
    "title": "loss.nn.EntropyLoss",
    "section": "",
    "text": "loss.nn.EntropyLoss(\n    self\n    nu=1.0\n    name=None\n    *\n    axis=-1\n    keepdims=False\n    reduce=True\n    scalarisation=None\n    key=None\n)\nLoss based on the entropy of a categorical distribution.\nThis operates on probability tensors. For a version that operates on logits, see :class:EntropyLogitLoss.\n.. admonition:: Entropy\nThe entropy of a categorical distribution :math:`A` is defined as\n\n:math:`-\\mathbf{1}^\\intercal \\left(A \\circ \\log A\\right) \\mathbf{1}`\n\n(where :math:`\\log` denotes the elementwise logarithm).\n\n.. image:: ../_images/entropysimplex.svg\n    :width: 250\n    :align: center\n\n*Cartoon schematic of the contours of an entropy-like function over\ncategorical distributions. The function attains its maximum for the\ndistribution in which all outcomes are equiprobable. The function can\nbecome smaller without bound away from this maximum. The superposed\ntriangle represents the probability simplex. By pre-transforming the\npenalised weights to constrain them to the simplex, the entropy\nfunction is bounded and attains a separate minimum for each\ndeterministic distribution.*\n\nPenalising the entropy promotes concentration of weight into a single\ncategory. This has applications in problem settings such as\nparcellation, when more deterministic parcel assignments are desired.\n.. warning:: Entropy is a concave function. Minimising it without constraint affords an unbounded capacity for reducing the loss. This is almost certainly undesirable. For this reason, it is recommended that some constraint be imposed on the input set when placing a penalty on entropy. One possibility is using a :doc:probability simplex parameter mapper &lt;hypercoil.init.mapparam.ProbabilitySimplexParameter&gt; to first project the input weights onto the probability simplex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nOptional[str]\nDesignated name of the loss function. It is not required that this be specified, but it is recommended to ensure that the loss function can be identified in the context of a reporting utilities. If not explicitly specified, the name will be inferred from the class name and the name of the scoring function.\nNone\n\n\nnu\nfloat\nLoss strength multiplier. This is a scalar multiplier that is applied to the loss value before it is returned. This can be used to modulate the relative contributions of different loss functions to the overall loss value. It can also be used to implement a schedule for the loss function, by dynamically adjusting the multiplier over the course of training.\n1.0\n\n\naxis\nint or sequence of ints, optional (default: -1)\nAxis or axes over which to compute the entropy.\n-1\n\n\nkeepdims\nbool, optional (default: True)\nAs in jax.numpy.sum.\nFalse\n\n\nreduce\nbool, optional (default: True)\nIf this is False, then the unsummed probability-weighted surprise is computed for each element of the input tensor. Otherwise, the entropy is computed over the specified axis or axes.\nTrue\n\n\nscalarisation\nOptional[Callable]\nThe scalarisation function to be used to aggregate the values returned by the scoring function. This function should take a single argument, which is a tensor of arbitrary shape, and return a single scalar value. By default, the mean scalarisation is used.\nNone",
    "crumbs": [
      "hypercoil",
      "loss.nn.EntropyLoss"
    ]
  },
  {
    "objectID": "api/loss.nn.EntropyLoss.html#parameters",
    "href": "api/loss.nn.EntropyLoss.html#parameters",
    "title": "loss.nn.EntropyLoss",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nname\nOptional[str]\nDesignated name of the loss function. It is not required that this be specified, but it is recommended to ensure that the loss function can be identified in the context of a reporting utilities. If not explicitly specified, the name will be inferred from the class name and the name of the scoring function.\nNone\n\n\nnu\nfloat\nLoss strength multiplier. This is a scalar multiplier that is applied to the loss value before it is returned. This can be used to modulate the relative contributions of different loss functions to the overall loss value. It can also be used to implement a schedule for the loss function, by dynamically adjusting the multiplier over the course of training.\n1.0\n\n\naxis\nint or sequence of ints, optional (default: -1)\nAxis or axes over which to compute the entropy.\n-1\n\n\nkeepdims\nbool, optional (default: True)\nAs in jax.numpy.sum.\nFalse\n\n\nreduce\nbool, optional (default: True)\nIf this is False, then the unsummed probability-weighted surprise is computed for each element of the input tensor. Otherwise, the entropy is computed over the specified axis or axes.\nTrue\n\n\nscalarisation\nOptional[Callable]\nThe scalarisation function to be used to aggregate the values returned by the scoring function. This function should take a single argument, which is a tensor of arbitrary shape, and return a single scalar value. By default, the mean scalarisation is used.\nNone",
    "crumbs": [
      "hypercoil",
      "loss.nn.EntropyLoss"
    ]
  },
  {
    "objectID": "api/functional.partialcorr.html",
    "href": "api/functional.partialcorr.html",
    "title": "functional.partialcorr",
    "section": "",
    "text": "functional.partialcorr(X, require_nonsingular=True, **params)\nPartial Pearson correlation of variables in a tensor batch.\nThe partial correlation is obtained by conditioning the covariance of each pair of variables on all other observed variables. It can be interpreted as a measurement of the direct relationship between each variable pair. The partial correlation is efficiently computed via successive inversion and normalisation of the covariance matrix, accompanied by negation of off-diagonal entries.\n:Dimension: Input : :math:(N, *, C, obs) or :math:(N, *, obs, C) N denotes batch size, * denotes any number of intervening dimensions, C denotes number of data channels or variables to be correlated, obs denotes number of observations per channel Weight : :math:(obs) or :math:(obs, obs) As above Output : :math:(N, *, C, C) As above\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\nTensor\nTensor containing a sample of multivariate observations. Each slice along the last axis corresponds to an observation, and each slice along the penultimate axis corresponds to a data channel or more generally a variable.\nrequired\n\n\nrequire_nonsingular\nbool\nIndicates that the covariance must be nonsingular. If this is False, then the Moore-Penrose pseudoinverse is computed instead of the inverse.\nTrue\n\n\nrowvar\nbool (default True)\nIndicates that the last axis of the input tensor is the observation axis and the penultimate axis is the variable axis. If False, then this relationship is transposed.\nrequired\n\n\nbias\nbool (default False)\nIndicates that the biased normalisation (i.e., division by N in the unweighted case) should be performed. By default, normalisation of the covariance is unbiased (i.e., division by N - 1).\nrequired\n\n\nddof\nint or None (default None)\nDegrees of freedom for normalisation. If this is specified, it overrides the normalisation factor automatically determined using the bias parameter.\nrequired\n\n\nweight\nTensor or None (default None)\nTensor containing importance or coupling weights for the observations. If this tensor is 1-dimensional, each entry weights the corresponding observation in the covariance computation. If it is 2-dimensional, then it must be square, symmetric, and positive semidefinite. In this case, diagonal entries again correspond to relative importances, while off-diagonal entries indicate coupling factors. For instance, a banded or multi-diagonal tensor can be used to specify inter-temporal coupling for a time series covariance.\nrequired\n\n\nl2\nnonnegative float (default 0)\nL2 regularisation term to add to the maximum likelihood estimate of the covariance matrix. This can be set to a positive value to obtain an intermediate for estimating the regularised inverse covariance.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nR\nTensor\nPartial Pearson correlation matrix of the variables in the input tensor.\n\n\n\n\n\n\ncorr: Pearson correlation matrix partialcov: Partial covariance matrix conditionalcorr: Conditional correlation matrix",
    "crumbs": [
      "hypercoil",
      "functional.partialcorr"
    ]
  },
  {
    "objectID": "api/functional.partialcorr.html#parameters",
    "href": "api/functional.partialcorr.html#parameters",
    "title": "functional.partialcorr",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nX\nTensor\nTensor containing a sample of multivariate observations. Each slice along the last axis corresponds to an observation, and each slice along the penultimate axis corresponds to a data channel or more generally a variable.\nrequired\n\n\nrequire_nonsingular\nbool\nIndicates that the covariance must be nonsingular. If this is False, then the Moore-Penrose pseudoinverse is computed instead of the inverse.\nTrue\n\n\nrowvar\nbool (default True)\nIndicates that the last axis of the input tensor is the observation axis and the penultimate axis is the variable axis. If False, then this relationship is transposed.\nrequired\n\n\nbias\nbool (default False)\nIndicates that the biased normalisation (i.e., division by N in the unweighted case) should be performed. By default, normalisation of the covariance is unbiased (i.e., division by N - 1).\nrequired\n\n\nddof\nint or None (default None)\nDegrees of freedom for normalisation. If this is specified, it overrides the normalisation factor automatically determined using the bias parameter.\nrequired\n\n\nweight\nTensor or None (default None)\nTensor containing importance or coupling weights for the observations. If this tensor is 1-dimensional, each entry weights the corresponding observation in the covariance computation. If it is 2-dimensional, then it must be square, symmetric, and positive semidefinite. In this case, diagonal entries again correspond to relative importances, while off-diagonal entries indicate coupling factors. For instance, a banded or multi-diagonal tensor can be used to specify inter-temporal coupling for a time series covariance.\nrequired\n\n\nl2\nnonnegative float (default 0)\nL2 regularisation term to add to the maximum likelihood estimate of the covariance matrix. This can be set to a positive value to obtain an intermediate for estimating the regularised inverse covariance.\nrequired",
    "crumbs": [
      "hypercoil",
      "functional.partialcorr"
    ]
  },
  {
    "objectID": "api/functional.partialcorr.html#returns",
    "href": "api/functional.partialcorr.html#returns",
    "title": "functional.partialcorr",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nR\nTensor\nPartial Pearson correlation matrix of the variables in the input tensor.",
    "crumbs": [
      "hypercoil",
      "functional.partialcorr"
    ]
  },
  {
    "objectID": "api/functional.partialcorr.html#see-also",
    "href": "api/functional.partialcorr.html#see-also",
    "title": "functional.partialcorr",
    "section": "",
    "text": "corr: Pearson correlation matrix partialcov: Partial covariance matrix conditionalcorr: Conditional correlation matrix",
    "crumbs": [
      "hypercoil",
      "functional.partialcorr"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API reference",
    "section": "",
    "text": "Differentiable programming for mapping brain function\n\n\n\nfunctional.corr\nPearson correlation of variables in a tensor batch.\n\n\nfunctional.partialcorr\nPartial Pearson correlation of variables in a tensor batch.\n\n\nloss.nn.EntropyLoss\nLoss based on the entropy of a categorical distribution.",
    "crumbs": [
      "API reference"
    ]
  },
  {
    "objectID": "api/index.html#hypercoil",
    "href": "api/index.html#hypercoil",
    "title": "API reference",
    "section": "",
    "text": "Differentiable programming for mapping brain function\n\n\n\nfunctional.corr\nPearson correlation of variables in a tensor batch.\n\n\nfunctional.partialcorr\nPartial Pearson correlation of variables in a tensor batch.\n\n\nloss.nn.EntropyLoss\nLoss based on the entropy of a categorical distribution.",
    "crumbs": [
      "API reference"
    ]
  }
]