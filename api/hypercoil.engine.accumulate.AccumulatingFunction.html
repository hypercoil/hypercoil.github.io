
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>AccumulatingFunction &#8212; hypercoil prototype (unreleased) documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="eval: Benchmarks and evaluation" href="../eval.html" />
    <link rel="prev" title="Accumulator" href="hypercoil.engine.accumulate.Accumulator.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../modules.html">
  API reference
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     data
    </span>
   </code>
   : Data engineering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="hypercoil.data.bids.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       bids
      </span>
     </code>
     : BIDS interfaces
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.bids.fmriprep_references.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         fmriprep_references
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.bids.fMRIPrepDataset.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         fMRIPrepDataset
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.bids.LightBIDSLayout.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         LightBIDSLayout
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.bids.BIDSObjectFactory.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         BIDSObjectFactory
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.bids.LightBIDSObject.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         LightBIDSObject
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.data.collate.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       collate
      </span>
     </code>
     : Batch collation functionality
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="hypercoil.data.dataref.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       dataref
      </span>
     </code>
     : Data references
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.dataref.DataReference.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         DataReference
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.dataref.DataQuery.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         DataQuery
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.dataref.data_references.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         data_references
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="hypercoil.data.dataset.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       dataset
      </span>
     </code>
     : Referenced datasets
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.dataset.ReferencedDataset.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         ReferencedDataset
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.dataset.ReferencedDataLoader.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         ReferencedDataLoader
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="hypercoil.data.functional.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       functional
      </span>
     </code>
     : Data transform functions
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.functional.general.html">
       General use
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.functional.filesystem.html">
       I/O and filesystem
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.functional.tensor.html">
       Tensor casting and binding
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.functional.dataframe.html">
       Data frames
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.functional.neuroimage.html">
       Neuroimaging datasets
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.functional.metadata.html">
       Metadata
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.functional.missing.html">
       Missing values
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.functional.timeseries.html">
       Time series
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="hypercoil.data.hcp.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       hcp
      </span>
     </code>
     : HCP interfaces
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.data.hcp.hcp_references.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         hcp_references
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../engine.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     engine
    </span>
   </code>
   : Differentiable engine
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="hypercoil.engine.accumulate.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       accumulate
      </span>
     </code>
     : Local gradient accumulation
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.engine.accumulate.Accumulator.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         Accumulator
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       <code class="docutils literal notranslate">
        <span class="pre">
         AccumulatingFunction
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../eval.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     eval
    </span>
   </code>
   : Benchmarks and evaluation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../functional.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     functional
    </span>
   </code>
   : Functions and functionals
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../init.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     init
    </span>
   </code>
   : Initialisation schemes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="hypercoil.init.atlas.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       atlas
      </span>
     </code>
     : Atlas initialisation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.BaseAtlas.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         BaseAtlas
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.DirichletInitBaseAtlas.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         DirichletInitBaseAtlas
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.DiscreteVolumetricAtlas.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         DiscreteVolumetricAtlas
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.MultiVolumetricAtlas.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         MultiVolumetricAtlas
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.MultifileVolumetricAtlas.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         MultifileVolumetricAtlas
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.CortexSubcortexCIfTIAtlas.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         CortexSubcortexCIfTIAtlas
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.DirichletInitVolumetricAtlas.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         DirichletInitVolumetricAtlas
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.DirichletInitSurfaceAtlas.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         DirichletInitSurfaceAtlas
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hypercoil.init.atlas.AtlasInit.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         AtlasInit
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../loss.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     loss
    </span>
   </code>
   : Loss and regularisation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.loss.cmass.Compactness.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       Compactness
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.loss.cmass.HemisphericTether.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       HemisphericTether
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.loss.determinant.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       determinant
      </span>
     </code>
     : Log determinant-based losses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.loss.dispersion.VectorDispersion.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       VectorDispersion
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.loss.entropy.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       Entropy
      </span>
     </code>
     and
     <code class="docutils literal notranslate">
      <span class="pre">
       SoftmaxEntropy
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.loss.equilibrium.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       Equilibrium
      </span>
     </code>
     and
     <code class="docutils literal notranslate">
      <span class="pre">
       SoftmaxEquilibrium
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.loss.modularity.ModularityLoss.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       ModularityLoss
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypercoil.loss.secondmoment.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       secondmoment
      </span>
     </code>
     : Second moment-based losses
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../nn.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     nn
    </span>
   </code>
   : Neural network modules
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../viz.html">
   <code class="docutils literal notranslate">
    <span class="pre">
     viz
    </span>
   </code>
   : Visualisation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="accumulatingfunction">
<h1><code class="docutils literal notranslate"><span class="pre">AccumulatingFunction</span></code><a class="headerlink" href="#accumulatingfunction" title="Permalink to this headline">#</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="hypercoil.engine.accumulate.AccumulatingFunction">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hypercoil.engine.accumulate.</span></span><span class="sig-name descname"><span class="pre">AccumulatingFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hypercoil.engine.accumulate.AccumulatingFunction" title="Permalink to this definition">#</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">autograd.Function</span></code> that supports local gradient accumulation.</p>
<p>For many use cases, it will make most sense to use an
<span class="xref std std-doc">Accumuline</span>
instead of directly interfacing with this class.</p>
<p>To use an <code class="docutils literal notranslate"><span class="pre">AccumulatingFunction</span></code>, we need to begin by defining an
<a class="reference internal" href="hypercoil.engine.accumulate.Accumulator.html"><span class="doc">Accumulator</span></a>
to perform the accumulation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span> <span class="o">=</span> <span class="n">Accumulator</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">gradient</span><span class="o">=</span><span class="n">model_grad</span><span class="p">,</span>
    <span class="n">retain_dims</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>We will also need a function to operationalise the backward pass through
the <code class="docutils literal notranslate"><span class="pre">AccumulatingFunction</span></code>. The backward function should take as inputs
(i) all of the tensors that encode the back-propagated gradient of the
loss node with respect to each output of the <code class="docutils literal notranslate"><span class="pre">AccumulatingFunction</span></code> and
(ii) all of the local derivatives accumulated by the <code class="docutils literal notranslate"><span class="pre">Accumulator</span></code> we’ve
created. For the case of matrix-matrix multiplication, we can reasonably
use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">accbwd</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">grad_local</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">grad_output</span> <span class="o">@</span> <span class="n">grad_local</span><span class="p">,</span>
</pre></div>
</div>
<p>We’ll also need a quick function to map from samples input to the
<code class="docutils literal notranslate"><span class="pre">AccumulatingFunction</span></code> to arguments to the <code class="docutils literal notranslate"><span class="pre">Accumulator</span></code>’s specified
<code class="docutils literal notranslate"><span class="pre">model</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">argmap</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">T</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;X&#39;</span> <span class="p">:</span> <span class="n">T</span><span class="p">}</span>
</pre></div>
</div>
<p>We can now apply our <code class="docutils literal notranslate"><span class="pre">AccumulatingFunction</span></code> to input samples. Here we’re
accumulating the local derivative of the matrix multiplication operation
with respect to one of the matrices being multiplied, <code class="docutils literal notranslate"><span class="pre">W</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">T0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">accfwd</span> <span class="o">=</span> <span class="n">AccumulatingFunction</span><span class="o">.</span><span class="n">apply</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">accfwd</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">argmap</span><span class="p">,</span> <span class="n">passmap</span><span class="p">,</span> <span class="n">T0</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<span class="n">T1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">accfwd</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">argmap</span><span class="p">,</span> <span class="n">passmap</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
</pre></div>
</div>
<p>Each call to <code class="docutils literal notranslate"><span class="pre">accfwd</span></code> above will accumulate the local derivative in the
provided <code class="docutils literal notranslate"><span class="pre">acc</span></code> object and will also append any outputs to the <code class="docutils literal notranslate"><span class="pre">out</span></code>
iterable that we provided in our call. When we’ve collected all of the
outputs we need in <code class="docutils literal notranslate"><span class="pre">out</span></code>, we make a terminal call to <code class="docutils literal notranslate"><span class="pre">accfwd</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">accfwd</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">bwd</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
</pre></div>
</div>
<p>The terminal call is made by setting the <code class="docutils literal notranslate"><span class="pre">terminate</span></code> argument to True.
We should not pass new data to the accumulating function during the
terminal call, as it will not be used. The terminal call caches the
accumulated derivative for the backward pass and then clears all
accumulated data from the <code class="docutils literal notranslate"><span class="pre">Accumulator</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Only the terminal call of an <code class="docutils literal notranslate"><span class="pre">AccumulatingFunction</span></code> is capable of
back-propagating gradients. All other calls will not track tensor
history and will block any gradients that they receive from being
further propagated.</p>
</div>
<p>We can use a <code class="docutils literal notranslate"><span class="pre">partial</span></code> to simplify usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">accfwd</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">AccumulatingFunction</span><span class="o">.</span><span class="n">apply</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">argmap</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>acc</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Accumulator</span></code></span></dt><dd><p>Accumulator object for accumulating the local derivative over calls
to the function.</p>
</dd>
<dt><strong>backward</strong><span class="classifier">callable</span></dt><dd><p>Backward pass through the function. This should take as inputs (i) all
of the tensors that encode the back-propagated gradient of the
loss node with respect to each output of the <code class="docutils literal notranslate"><span class="pre">AccumulatingFunction</span></code>
and (ii) all of the local derivatives accumulated by the
<code class="docutils literal notranslate"><span class="pre">Accumulator</span></code> and should return the back-propagated gradient with
respect to each input parameter provided in <code class="docutils literal notranslate"><span class="pre">params</span></code>.</p>
</dd>
<dt><strong>argmap</strong><span class="classifier">callable</span></dt><dd><p>Map from samples input to the function to mappings representing
arguments to the <code class="docutils literal notranslate"><span class="pre">Accumulator</span></code>.</p>
</dd>
<dt><strong>sample</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tensor</span></code> or iterable(<code class="docutils literal notranslate"><span class="pre">tensor</span></code>)</span></dt><dd><p>Input sample to be processed. The gradient with respect to the input
sample is not returned.</p>
</dd>
<dt><strong>out</strong><span class="classifier">iterable</span></dt><dd><p>Iterable containing accumulated outputs thus far. The output created
at each call is appended to this iterable.</p>
</dd>
<dt><strong>terminate</strong><span class="classifier">bool</span></dt><dd><p>Indicates that accumulation should be terminated, and a new node
containing the accumulated local derivative should be added to the
computational graph. Only the terminal call will retain tensor
history, and only the terminal node accordingly backpropagates
received gradient. However, the terminal call does not do any data
processing or new accumulation, so it should not receive previously
unseen input data.</p>
</dd>
<dt><strong>params</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tensor</span></code></span></dt><dd><p>Parameters with respect to which the accumulated gradient should be
computed and backpropagated. The <code class="docutils literal notranslate"><span class="pre">gradient</span></code> parameter provided to
the input <code class="docutils literal notranslate"><span class="pre">Accumulator</span></code> should define local gradients with respect
to each of these parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">iterable</span></dt><dd><p>Iterable containing all previously accumulated outputs provided as
parameters to <code class="docutils literal notranslate"><span class="pre">out</span></code>, together with a new output from the current
call to the internal <code class="docutils literal notranslate"><span class="pre">model</span></code> of the input <code class="docutils literal notranslate"><span class="pre">Accumulator</span></code>. For the
terminal call, this will instead be a tuple of collated tensors.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hypercoil.engine.accumulate.AccumulatingFunction.backward" title="hypercoil.engine.accumulate.AccumulatingFunction.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a>(ctx, *grad_output)</p></td>
<td><p>Defines a formula for differentiating the operation with backward mode automatic differentiation (alias to the vjp function).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hypercoil.engine.accumulate.AccumulatingFunction.forward" title="hypercoil.engine.accumulate.AccumulatingFunction.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(ctx, acc, backward, argmap, sample, ...)</p></td>
<td><p>Performs the operation.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods Documentation</p>
<dl class="py method">
<dt class="sig sig-object py" id="hypercoil.engine.accumulate.AccumulatingFunction.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hypercoil.engine.accumulate.AccumulatingFunction.apply" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hypercoil.engine.accumulate.AccumulatingFunction.forward">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">argmap</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">terminate</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hypercoil.engine.accumulate.AccumulatingFunction.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on <cite>ctx</cite> (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
<code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_backward()</span></code> if they are intended to be used in
<code class="docutils literal notranslate"><span class="pre">backward</span></code> (equivalently, <code class="docutils literal notranslate"><span class="pre">vjp</span></code>) or <code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_forward()</span></code>
if they are intended to be used for in <code class="docutils literal notranslate"><span class="pre">jvp</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hypercoil.engine.accumulate.AccumulatingFunction.backward">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">grad_output</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hypercoil.engine.accumulate.AccumulatingFunction.backward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines a formula for differentiating the operation with backward mode
automatic differentiation (alias to the vjp function).</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs as the <a class="reference internal" href="#hypercoil.engine.accumulate.AccumulatingFunction.forward" title="hypercoil.engine.accumulate.AccumulatingFunction.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
<a class="reference internal" href="#hypercoil.engine.accumulate.AccumulatingFunction.forward" title="hypercoil.engine.accumulate.AccumulatingFunction.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#hypercoil.engine.accumulate.AccumulatingFunction.backward" title="hypercoil.engine.accumulate.AccumulatingFunction.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#hypercoil.engine.accumulate.AccumulatingFunction.forward" title="hypercoil.engine.accumulate.AccumulatingFunction.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

</dd></dl>

</section>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, the development team.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>